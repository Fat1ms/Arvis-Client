# üöÄ Phase 3: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
## –ü–æ–ª–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (–æ–∫—Ç—è–±—Ä—å-–¥–µ–∫–∞–±—Ä—å 2025)

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞**: 1.0  
**–î–∞—Ç–∞**: 21 –æ–∫—Ç—è–±—Ä—è 2025  
**–°—Ç–∞—Ç—É—Å**: üü° –í –Ω–∞—á–∞–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏  
**–í–µ—Ä—Å–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**: v1.5.1 ‚Üí v1.6.0  

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
1. [–û–±–∑–æ—Ä Phase 3](#–æ–±–∑–æ—Ä-phase-3)
2. [–§–∏—á–∏ –∏ –∏—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã](#—Ñ–∏—á–∏-–∏-–∏—Ö-–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã)
3. [–î–µ—Ç–∞–ª—å–Ω—ã–µ –ø–ª–∞–Ω—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏](#–¥–µ—Ç–∞–ª—å–Ω—ã–µ-–ø–ª–∞–Ω—ã-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
4. [–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å](#–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏-–∏-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
5. [Testing Strategy](#testing-strategy)
6. [Git Workflow](#git-workflow)
7. [Timelines](#timelines)
8. [Post-Implementation Checklist](#post-implementation-checklist)

---

## üéØ –û–±–∑–æ—Ä Phase 3

### –¶–µ–ª–∏
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LLM streaming –¥–ª—è Gemma 2B –∏ TTS buffering
- **Reliability**: –°–∏—Å—Ç–µ–º–∞ health checks –∏ metrics –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- **Maintainability**: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ monolithic arvis_core.py –Ω–∞ –º–æ–¥—É–ª–∏
- **Quality**: –ü–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ unit tests (80%+)
- **Future-proofing**: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ PyQt6 –∏ —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### Key Metrics (—Ü–µ–ª–µ–≤—ã–µ)
- TTFT (Time To First Token): < 500ms (Gemma 2B)
- Throughput: > 15 tokens/sec (Gemma 2B)
- Health check duration: < 3 sec (all checks)
- Test coverage: ‚â• 80% –¥–ª—è core modules
- Code complexity: arvis_core.py –≤ 5 —Ñ–∞–π–ª–∞—Ö < 400 —Å—Ç—Ä–æ–∫ –∫–∞–∂–¥—ã–π

---

## üî• –§–∏—á–∏ –∏ –∏—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã

| # | –§–∏—á–∞ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | –°–ª–æ–∂–Ω–æ—Å—Ç—å | Est. Days | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç |
|---|------|-----------|-----------|----------|-----------|
| 1 | Bark TTS Factory pattern | üî¥ HIGH | ‚≠ê‚≠ê‚≠ê | 5 | - |
| 2 | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LLM streaming | üî¥ HIGH | ‚≠ê‚≠ê‚≠ê | 6 | LLMClient |
| 3 | Health checks —Å–∏—Å—Ç–µ–º–∞ | üü° MEDIUM | ‚≠ê‚≠ê | 4 | STT, TTS, LLM |
| 4 | –†–∞–∑–¥–µ–ª–∏—Ç—å arvis_core.py | üü° MEDIUM | ‚≠ê‚≠ê‚≠ê‚≠ê | 7 | - |
| 5 | Metrics collector | üü° MEDIUM | ‚≠ê‚≠ê | 4 | Health checks |
| 6 | Unit tests (80%) | üü° MEDIUM | ‚≠ê‚≠ê | 8 | 1-5 |
| 7 | –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ PyQt6 | üîµ LOW | ‚≠ê‚≠ê | 3 | - |
| 8 | –£–ª—É—á—à–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥ | üîµ LOW | ‚≠ê‚≠ê | 4 | - |
| 9 | –°–∏—Å—Ç–µ–º–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π | üîµ LOW | ‚≠ê‚≠ê | 3 | - |

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä—è–¥–æ–∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
1. –§–∏—á–∞ #1 (TTS Factory) ‚Äî —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö TTS-related
2. –§–∏—á–∞ #2 (LLM streaming) ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
3. –§–∏—á–∞ #3 (Health checks) ‚Äî –Ω—É–∂–Ω–∞ –¥–ª—è #5
4. –§–∏—á–∞ #4 (arvis_core split) ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ #2-3
5. –§–∏—á–∞ #5 (Metrics) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç results –∏–∑ #1-3
6. –§–∏—á–∞ #6 (Tests) ‚Äî –ø–æ—Å–ª–µ #1-5, –ø–æ–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ
7. –§–∏—á–∏ #7-9 ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≤ –∫–æ–Ω—Ü–µ

---

## üìê –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø–ª–∞–Ω—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### FEATURE 1Ô∏è‚É£: Bark TTS Factory Pattern

#### 1.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
```
modules/tts_factory.py
‚îú‚îÄ‚îÄ TTSFactory (class)
‚îÇ   ‚îú‚îÄ‚îÄ create_engine(engine_name, config) ‚Üí TTSEngineBase
‚îÇ   ‚îú‚îÄ‚îÄ list_available_engines() ‚Üí List[str]
‚îÇ   ‚îî‚îÄ‚îÄ validate_engine_config(engine_name, config) ‚Üí bool
‚îÇ
‚îú‚îÄ‚îÄ TTSEngineBase (abstract)
‚îÇ   ‚îú‚îÄ‚îÄ speak(text, stream=False)
‚îÇ   ‚îú‚îÄ‚îÄ speak_streaming(text, chunk_callback)
‚îÇ   ‚îú‚îÄ‚îÄ stop()
‚îÇ   ‚îú‚îÄ‚îÄ get_status() ‚Üí Dict
‚îÇ   ‚îî‚îÄ‚îÄ get_config() ‚Üí Dict
‚îÇ
‚îú‚îÄ‚îÄ SileroTTSEngine (existing, refactored)
‚îú‚îÄ‚îÄ BarkTTSEngine (new)
‚îú‚îÄ‚îÄ SAPITTSEngine (existing, refactored)
‚îî‚îÄ‚îÄ MockTTSEngine (for testing)

modules/bark_tts_engine.py
‚îú‚îÄ‚îÄ BarkTTSEngine
‚îÇ   ‚îú‚îÄ‚îÄ __init__(config, logger)
‚îÇ   ‚îú‚îÄ‚îÄ _load_model_async() ‚Üí Future
‚îÇ   ‚îú‚îÄ‚îÄ speak(text, stream=False) ‚Üí bool
‚îÇ   ‚îú‚îÄ‚îÄ speak_streaming(text, chunk_callback)
‚îÇ   ‚îú‚îÄ‚îÄ _synthesize_with_bark(text) ‚Üí np.ndarray
‚îÇ   ‚îú‚îÄ‚îÄ _stream_audio(audio_data, chunk_callback)
‚îÇ   ‚îî‚îÄ‚îÄ health_check() ‚Üí HealthCheckResult
```

#### 1.2 –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ Bark
```
–£—Å—Ç–∞–Ω–æ–≤–∫–∞:
pip install bark transformers[torch] soundfile numpy scipy torch torchaudio

–ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–∫–∞—á–∞–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ (~2 GB)
–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ~/.cache/huggingface/

Config –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (config.json):
{
  "tts": {
    "engine": "bark",  // "silero", "sapi", "bark"
    "bark": {
      "device": "cuda",  // "cpu", "cuda", "mps"
      "precision": "float32",  // "float32", "float16"
      "sample_rate": 24000,
      "chunk_duration_ms": 500,
      "voice": "v2/en_speaker_6",
      "temperature": 0.6,
      "top_p": 0.9,
      "top_k": 50
    }
  }
}
```

#### 1.3 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —à–∞–≥–∏

**–®–∞–≥ 1**: –°–æ–∑–¥–∞—Ç—å –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å
```python
# modules/tts_factory.py
class TTSEngineBase(ABC):
    @abstractmethod
    def speak(self, text: str, stream: bool = False) -> bool:
        """–°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –ø—Ä–æ–∏–≥—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç"""
        
    @abstractmethod
    def speak_streaming(self, text: str, chunk_callback: Callable) -> bool:
        """–ü–æ—Ç–æ–∫–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ —Å callback'–æ–º"""
        
    @abstractmethod
    def stop(self) -> None:
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ"""
        
    @abstractmethod
    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å engine'–∞"""
        
    def health_check(self) -> HealthCheckResult:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞)"""
        return HealthCheckResult(
            component="tts",
            status=HealthStatus.HEALTHY,
            message="TTS engine ready"
        )
```

**–®–∞–≥ 2**: Refactor —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö engines
- Refactor `SileroTTSEngine` ‚Üê –Ω–∞—Å–ª–µ–¥—É–µ—Ç `TTSEngineBase`
- Refactor `SAPITTSEngine` ‚Üê –Ω–∞—Å–ª–µ–¥—É–µ—Ç `TTSEngineBase`
- –î–æ–±–∞–≤–∏—Ç—å `speak_streaming()` –≤ `SileroTTSEngine` (–µ—Å–ª–∏ –Ω–µ—Ç)

**–®–∞–≥ 3**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å BarkTTSEngine
```python
# modules/bark_tts_engine.py
class BarkTTSEngine(TTSEngineBase):
    def __init__(self, config: Config, logger):
        self.config = config
        self.logger = logger
        self.model = None
        self.processor = None
        self.device = config.get("tts.bark.device", "cpu")
        self._is_speaking = False
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        self._load_model_async()
    
    def _load_model_async(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ"""
        from utils.async_manager import task_manager
        
        def load():
            try:
                from bark import SAMPLE_RATE, generate_audio, preload_models
                preload_models(device=self.device)
                self.logger.info(f"Bark model loaded on {self.device}")
                return True
            except Exception as e:
                self.logger.error(f"Failed to load Bark: {e}")
                return False
        
        task_manager.run_async("bark_load", load)
    
    def speak_streaming(self, text: str, chunk_callback: Callable[[bytes], None]) -> bool:
        """–ü–æ—Ç–æ–∫–æ–≤—ã–π —Å–∏–Ω—Ç–µ–∑ Bark"""
        from bark import SAMPLE_RATE, generate_audio
        import soundfile as sf
        import io
        
        if not self.model:
            self.logger.warning("Bark model not loaded yet")
            return False
        
        try:
            # –°–∏–Ω—Ç–µ–∑ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è Bark –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è streaming, —Ç–æ–ª—å–∫–æ —á–∞–Ω–∫–∏ –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º)
            audio_array = generate_audio(
                text,
                voice_preset=self.config.get("tts.bark.voice", "v2/en_speaker_6"),
                temperature=self.config.get("tts.bark.temperature", 0.6)
            )
            
            # –°—Ç—Ä–∏–º–∏–º –∞—É–¥–∏–æ —á–∞–Ω–∫–∞–º–∏
            self._stream_audio(audio_array, chunk_callback, SAMPLE_RATE)
            return True
        except Exception as e:
            self.logger.error(f"Bark synthesis failed: {e}")
            return False
    
    def _stream_audio(self, audio_array, chunk_callback, sample_rate):
        """–°—Ç—Ä–∏–º–∏—Ç—å –∞—É–¥–∏–æ –º–∞—Å—Å–∏–≤ —á–∞–Ω–∫–∞–º–∏"""
        chunk_samples = int(sample_rate * self.config.get("tts.bark.chunk_duration_ms", 500) / 1000)
        
        for i in range(0, len(audio_array), chunk_samples):
            chunk = audio_array[i:i+chunk_samples]
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ PCM bytes
            pcm_bytes = (chunk * 32767).astype(np.int16).tobytes()
            chunk_callback(pcm_bytes)
            self._is_speaking = True
        
        self._is_speaking = False
```

**–®–∞–≥ 4**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Factory
```python
# modules/tts_factory.py
class TTSFactory:
    _engines = {
        "silero": "modules.silero_tts_engine:SileroTTSEngine",
        "bark": "modules.bark_tts_engine:BarkTTSEngine",
        "sapi": "modules.system_tts:SAPITTSEngine",
    }
    
    @classmethod
    def create_engine(cls, engine_name: str, config: Config, logger) -> TTSEngineBase:
        """–°–æ–∑–¥–∞—Ç—å TTS engine –ø–æ –∏–º–µ–Ω–∏"""
        if engine_name not in cls._engines:
            raise ValueError(f"Unknown TTS engine: {engine_name}")
        
        # Dynamic import
        module_path, class_name = cls._engines[engine_name].rsplit(":", 1)
        module = __import__(module_path, fromlist=[class_name])
        engine_class = getattr(module, class_name)
        
        return engine_class(config, logger)
    
    @classmethod
    def list_available_engines(cls) -> List[str]:
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö engines"""
        return list(cls._engines.keys())
```

**–®–∞–≥ 5**: –û–±–Ω–æ–≤–∏—Ç—å ArvisCore
```python
# src/core/arvis_core.py
def init_tts_engine_async(self):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å TTS engine —á–µ—Ä–µ–∑ factory"""
    from modules.tts_factory import TTSFactory
    
    engine_name = self.config.get("tts.engine", "silero")
    try:
        self.tts_engine = TTSFactory.create_engine(engine_name, self.config, self.logger)
        self.logger.info(f"TTS engine initialized: {engine_name}")
    except Exception as e:
        self.logger.error(f"Failed to initialize TTS: {e}")
        self.error_occurred.emit(f"TTS initialization failed: {e}")
```

#### 1.4 Testing –¥–ª—è TTS Factory
```python
# tests/unit/test_tts_factory.py
import pytest
from modules.tts_factory import TTSFactory, TTSEngineBase
from config.config import Config

class TestTTSFactory:
    def test_create_engine_silero(self):
        """–°–æ–∑–¥–∞—Ç—å Silero engine"""
        config = Config()
        engine = TTSFactory.create_engine("silero", config, logger)
        assert isinstance(engine, TTSEngineBase)
    
    def test_create_engine_bark(self):
        """–°–æ–∑–¥–∞—Ç—å Bark engine"""
        config = Config()
        config.set("tts.bark.device", "cpu")  # –ë—ã—Å—Ç—Ä–µ–µ –Ω–∞ —Ç–µ—Å—Ç–∞—Ö
        engine = TTSFactory.create_engine("bark", config, logger)
        assert isinstance(engine, TTSEngineBase)
    
    def test_create_engine_invalid(self):
        """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –Ω–µ–≤–µ—Ä–Ω–æ–º engine"""
        with pytest.raises(ValueError):
            TTSFactory.create_engine("invalid", config, logger)
    
    def test_list_available_engines(self):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö engines"""
        engines = TTSFactory.list_available_engines()
        assert "silero" in engines
        assert "bark" in engines
    
    @pytest.mark.slow
    def test_bark_speak_streaming(self):
        """–¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ Bark"""
        config = Config()
        config.set("tts.bark.device", "cpu")
        engine = TTSFactory.create_engine("bark", config, logger)
        
        chunks = []
        def on_chunk(data):
            chunks.append(data)
        
        result = engine.speak_streaming("Hello world", on_chunk)
        assert result is True
        assert len(chunks) > 0
```

---

### FEATURE 2Ô∏è‚É£: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è LLM Streaming –¥–ª—è Gemma 2B

#### 2.1 –ü—Ä–æ–±–ª–µ–º–∞ –∏ —Ä–µ—à–µ–Ω–∏–µ

**–ü—Ä–æ–±–ª–µ–º–∞**:
- –ü–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω –ø—Ä–∏—Ö–æ–¥–∏—Ç ~800ms (TTFT high)
- –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å < 10 tokens/sec –Ω–∞ Gemma 2B
- UI –∑–∞–≤–∏—Å–∞–µ—Ç –ø—Ä–∏ —Å—Ç—Ä–∏–º–∏–Ω–≥–µ –±–æ–ª—å—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
- Buffering –Ω–µ –æ–ø—Ç–∏–º–∞–ª–µ–Ω –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–π

**–†–µ—à–µ–Ω–∏–µ**:
- Adaptive buffering (–º–∏–Ω–∏–º—É–º 20 —Å–∏–º–≤–æ–ª–æ–≤ –ò–õ–ò –≥—Ä–∞–Ω–∏—Ü–∞ —Å–ª–æ–≤–∞)
- Batch processing –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è throughput
- –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ö–í–ò–ù/–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
- Quantization detection –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- Async buffering –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ UI

#### 2.2 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
```
modules/llm_streaming_optimizer.py
‚îú‚îÄ‚îÄ LLMStreamingOptimizer (class)
‚îÇ   ‚îú‚îÄ‚îÄ optimize_stream(stream_generator, config) ‚Üí Generator
‚îÇ   ‚îú‚îÄ‚îÄ detect_quantization(model_path) ‚Üí str
‚îÇ   ‚îú‚îÄ‚îÄ calculate_optimal_batch_size(model_info) ‚Üí int
‚îÇ   ‚îú‚îÄ‚îÄ get_performance_stats() ‚Üí Dict
‚îÇ   ‚îî‚îÄ‚îÄ reset_stats()
‚îÇ
‚îî‚îÄ‚îÄ StreamBuffer
    ‚îú‚îÄ‚îÄ add_chunk(text: str)
    ‚îú‚îÄ‚îÄ get_buffer() ‚Üí str  (if min_size or boundary reached)
    ‚îú‚îÄ‚îÄ flush() ‚Üí str
    ‚îî‚îÄ‚îÄ is_ready() ‚Üí bool

modules/llm_performance_monitor.py
‚îú‚îÄ‚îÄ LLMPerformanceMonitor
‚îÇ   ‚îú‚îÄ‚îÄ track_token(token_num, time, token_text)
‚îÇ   ‚îú‚îÄ‚îÄ get_ttft() ‚Üí float (Time To First Token)
‚îÇ   ‚îú‚îÄ‚îÄ get_throughput() ‚Üí float (tokens/sec)
‚îÇ   ‚îú‚îÄ‚îÄ get_latency() ‚Üí float (avg token latency)
‚îÇ   ‚îî‚îÄ‚îÄ get_report() ‚Üí Dict
```

#### 2.3 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–®–∞–≥ 1**: –°–æ–∑–¥–∞—Ç—å Stream Buffer —Å adaptive logic
```python
# modules/llm_streaming_optimizer.py
class StreamBuffer:
    MIN_CHUNK_SIZE = 20  # —Å–∏–º–≤–æ–ª–æ–≤
    WORD_BOUNDARIES = {'.', ',', '!', '?', ';', ':', '\n', ' '}
    
    def __init__(self, min_size: int = 20, word_boundary: bool = True):
        self.min_size = min_size
        self.word_boundary = word_boundary
        self.buffer = ""
    
    def add_chunk(self, text: str) -> Optional[str]:
        """
        –î–æ–±–∞–≤–∏—Ç—å —á–∞–Ω–∫ —Ç–µ–∫—Å—Ç–∞.
        –í–µ—Ä–Ω—É—Ç—å –≥–æ—Ç–æ–≤—ã–π –±—É—Ñ–µ—Ä –µ—Å–ª–∏:
        1. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤ (>= min_size) –ò –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–∏–º–≤–æ–ª –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ —Å–ª–æ–≤–∞
        2. –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤ –∏ word_boundary=False
        """
        self.buffer += text
        
        if len(self.buffer) >= self.min_size:
            if self.word_boundary:
                # –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É —Å–ª–æ–≤–∞
                for i in range(len(self.buffer) - 1, -1, -1):
                    if self.buffer[i] in self.WORD_BOUNDARIES:
                        result = self.buffer[:i+1]
                        self.buffer = self.buffer[i+1:]
                        return result
                # –ï—Å–ª–∏ –Ω–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã, –≤—Å–µ —Ä–∞–≤–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
                if len(self.buffer) > self.min_size * 2:
                    return self.buffer
            else:
                result = self.buffer[:self.min_size]
                self.buffer = self.buffer[self.min_size:]
                return result
        return None
    
    def flush(self) -> str:
        """–í–µ—Ä–Ω—É—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ"""
        result = self.buffer
        self.buffer = ""
        return result
    
    def is_empty(self) -> bool:
        return len(self.buffer) == 0
```

**–®–∞–≥ 2**: –°–æ–∑–¥–∞—Ç—å Performance Monitor
```python
# modules/llm_performance_monitor.py
import time
from typing import List, Tuple

class LLMPerformanceMonitor:
    def __init__(self):
        self.tokens: List[Tuple[int, float, str]] = []  # (num, timestamp, text)
        self.start_time = None
        self.first_token_time = None
    
    def start_generation(self):
        """–ù–∞—á–∞—Ç—å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ"""
        self.tokens.clear()
        self.start_time = time.time()
        self.first_token_time = None
    
    def track_token(self, token_num: int, token_text: str):
        """–û—Ç—Å–ª–µ–¥–∏—Ç—å —Ç–æ–∫–µ–Ω"""
        current_time = time.time()
        self.tokens.append((token_num, current_time, token_text))
        
        if token_num == 1 and not self.first_token_time:
            self.first_token_time = current_time
    
    def get_ttft(self) -> float:
        """Time To First Token (–º—Å)"""
        if not self.first_token_time or not self.start_time:
            return 0.0
        return (self.first_token_time - self.start_time) * 1000
    
    def get_throughput(self) -> float:
        """–¢–æ–∫–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥—É"""
        if len(self.tokens) < 2:
            return 0.0
        
        first_token_time = self.tokens[0][1]
        last_token_time = self.tokens[-1][1]
        elapsed = last_token_time - first_token_time
        
        if elapsed == 0:
            return 0.0
        
        token_count = len(self.tokens)
        return token_count / elapsed
    
    def get_latency(self) -> float:
        """–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Ç–æ–∫–µ–Ω–∞ (–º—Å)"""
        if len(self.tokens) < 2:
            return 0.0
        
        total_time = self.tokens[-1][1] - self.tokens[0][1]
        token_count = len(self.tokens) - 1
        
        return (total_time / token_count * 1000) if token_count > 0 else 0.0
    
    def get_report(self) -> dict:
        """–ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            "ttft_ms": round(self.get_ttft(), 2),
            "throughput_tokens_per_sec": round(self.get_throughput(), 2),
            "avg_token_latency_ms": round(self.get_latency(), 2),
            "total_tokens": len(self.tokens),
            "total_text": "".join(t[2] for t in self.tokens)
        }
```

**–®–∞–≥ 3**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Streaming Optimizer
```python
# modules/llm_streaming_optimizer.py
class LLMStreamingOptimizer:
    def __init__(self, config: Config, logger):
        self.config = config
        self.logger = logger
        self.monitor = LLMPerformanceMonitor()
        self.enabled = config.get("llm.stream_optimization_enabled", True)
    
    def optimize_stream(self, stream_generator, model_info: dict = None):
        """
        –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è stream generator —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.
        Yields: tuple (token_text, buffered_text_ready)
        """
        if not self.enabled:
            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ—Ç–æ–∫ –∫–∞–∫ –µ—Å—Ç—å
            for chunk in stream_generator:
                yield chunk
            return
        
        buffer = StreamBuffer(
            min_size=self.config.get("llm.buffer_threshold", 20),
            word_boundary=True
        )
        
        token_num = 0
        self.monitor.start_generation()
        
        try:
            for chunk in stream_generator:
                token_num += 1
                self.monitor.track_token(token_num, chunk)
                
                # –î–æ–±–∞–≤–∏—Ç—å –≤ –±—É—Ñ–µ—Ä –∏ –ø–æ–ª—É—á–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
                ready_text = buffer.add_chunk(chunk)
                
                if ready_text:
                    yield ready_text
            
            # –í–µ—Ä–Ω—É—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ
            remaining = buffer.flush()
            if remaining:
                yield remaining
        
        except Exception as e:
            self.logger.error(f"Stream optimization error: {e}")
            # –°–±—Ä–æ—Å–∏—Ç—å –±—É—Ñ–µ—Ä –ø—Ä–∏ –æ—à–∏–±–∫–µ
            remaining = buffer.flush()
            if remaining:
                yield remaining
        
        finally:
            # –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            report = self.monitor.get_report()
            self.logger.debug(f"LLM Performance: {report}")
    
    def detect_quantization(self, model_path: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: "float32", "float16", "int8", "unknown"
        """
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Ñ–∞–π–ª–∞ –∏–ª–∏ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        try:
            import os
            if not os.path.exists(model_path):
                return "unknown"
            
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä
            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            
            # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è Gemma 2B
            if size_mb < 1000:
                return "int8"  # –ö–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
            elif size_mb < 5000:
                return "float16"
            else:
                return "float32"
        except Exception as e:
            self.logger.warning(f"Failed to detect quantization: {e}")
            return "unknown"
    
    def calculate_optimal_batch_size(self, model_info: dict) -> int:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ—Å—É—Ä—Å–æ–≤.
        
        Args:
            model_info: {"vram_mb": 2000, "quantization": "float16", ...}
        """
        vram_mb = model_info.get("vram_mb", 2000)
        quantization = model_info.get("quantization", "float16")
        
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏
        base_batch = {"float32": 1, "float16": 2, "int8": 4}.get(quantization, 1)
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç VRAM
        if vram_mb >= 8000:
            return base_batch * 4
        elif vram_mb >= 4000:
            return base_batch * 2
        else:
            return base_batch
    
    def get_performance_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return self.monitor.get_report()
    
    def reset_stats(self):
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        self.monitor = LLMPerformanceMonitor()
```

**–®–∞–≥ 4**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ LLMClient
```python
# modules/llm_client.py (–º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ stream_response)

def stream_response(self, messages, **kwargs):
    """
    Stream response with optimization.
    """
    if not hasattr(self, 'stream_optimizer'):
        from modules.llm_streaming_optimizer import LLMStreamingOptimizer
        self.stream_optimizer = LLMStreamingOptimizer(self.config, self.logger)
    
    # –ü–æ–ª—É—á–∏—Ç—å —Å—ã—Ä–æ–π –ø–æ—Ç–æ–∫ –æ—Ç Ollama
    raw_stream = self._get_ollama_stream(messages, **kwargs)
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ç–æ–∫
    optimized_stream = self.stream_optimizer.optimize_stream(raw_stream)
    
    for chunk in optimized_stream:
        yield chunk
```

**–®–∞–≥ 5**: Config –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
```json
{
  "llm": {
    "stream_optimization_enabled": true,
    "buffer_threshold": 20,
    "word_boundary_buffering": true,
    "batch_size": "auto",
    "cache_kv": true,
    "cache_size_mb": 512
  }
}
```

#### 2.4 Testing –¥–ª—è LLM Streaming
```python
# tests/unit/test_llm_streaming_optimizer.py
import pytest
from modules.llm_streaming_optimizer import StreamBuffer, LLMStreamingOptimizer

class TestStreamBuffer:
    def test_buffer_adds_chunk(self):
        buf = StreamBuffer(min_size=20, word_boundary=False)
        result = buf.add_chunk("Hello ")
        assert result is None  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
        
        result = buf.add_chunk("world this is a test!")
        assert result is not None
        assert len(result) >= 20
    
    def test_buffer_respects_word_boundary(self):
        buf = StreamBuffer(min_size=5, word_boundary=True)
        result = buf.add_chunk("Hello")
        assert result is None  # –ù–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã
        
        result = buf.add_chunk(" ")
        assert result is not None
        assert result.endswith(" ")
    
    def test_buffer_flush(self):
        buf = StreamBuffer()
        buf.add_chunk("Hello")
        result = buf.flush()
        assert result == "Hello"
        assert buf.is_empty()

class TestLLMPerformanceMonitor:
    def test_ttft_calculation(self):
        monitor = LLMPerformanceMonitor()
        monitor.start_generation()
        
        import time
        time.sleep(0.1)
        monitor.track_token(1, "Hello")
        
        ttft = monitor.get_ttft()
        assert ttft >= 100  # –ú–∏–Ω–∏–º—É–º 100ms
        assert ttft < 1000  # –ú–∞–∫—Å–∏–º—É–º 1 —Å–µ–∫
    
    def test_throughput_calculation(self):
        monitor = LLMPerformanceMonitor()
        monitor.start_generation()
        
        # –î–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤
        import time
        for i in range(10):
            monitor.track_token(i, f"token{i}")
            time.sleep(0.01)
        
        throughput = monitor.get_throughput()
        assert throughput > 0
        assert throughput < 1000  # –†–∞–∑—É–º–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

class TestLLMStreamingOptimizer:
    def test_optimize_stream(self):
        config = Config()
        optimizer = LLMStreamingOptimizer(config, logger)
        
        # –°–∏–º—É–ª—è—Ü–∏—è –ø–æ—Ç–æ–∫–∞
        def mock_stream():
            chunks = ["Hello", " ", "world", "! ", "How", " are", " you?"]
            for chunk in chunks:
                yield chunk
        
        result = list(optimizer.optimize_stream(mock_stream()))
        assert len(result) > 0
        # –í—Å–µ —Ç–æ–∫–µ–Ω—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã
        full_text = "".join(result)
        assert "Hello world" in full_text
    
    def test_detect_quantization(self):
        optimizer = LLMStreamingOptimizer(Config(), logger)
        # –¢–µ—Å—Ç —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–æ–º
        result = optimizer.detect_quantization("/nonexistent/model")
        assert result in ["float32", "float16", "int8", "unknown"]
```

---

### FEATURE 3Ô∏è‚É£: Health Checks System

**[–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ]**

#### 3.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
utils/health_check.py
‚îú‚îÄ‚îÄ HealthStatus (enum: HEALTHY, DEGRADED, UNHEALTHY, UNKNOWN)
‚îú‚îÄ‚îÄ HealthCheckResult (dataclass)
‚îÇ   ‚îú‚îÄ‚îÄ component: str
‚îÇ   ‚îú‚îÄ‚îÄ status: HealthStatus
‚îÇ   ‚îú‚îÄ‚îÄ message: str
‚îÇ   ‚îú‚îÄ‚îÄ timestamp: float
‚îÇ   ‚îî‚îÄ‚îÄ details: Dict
‚îÇ
‚îú‚îÄ‚îÄ HealthChecker (facade)
‚îÇ   ‚îú‚îÄ‚îÄ check_all() ‚Üí List[HealthCheckResult]
‚îÇ   ‚îú‚îÄ‚îÄ check_component(name: str) ‚Üí HealthCheckResult
‚îÇ   ‚îú‚îÄ‚îÄ start_periodic_checks(interval_sec)
‚îÇ   ‚îú‚îÄ‚îÄ stop_periodic_checks()
‚îÇ   ‚îî‚îÄ‚îÄ get_last_results() ‚Üí Dict[str, HealthCheckResult]
‚îÇ
‚îî‚îÄ‚îÄ –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ checkers:
    ‚îú‚îÄ‚îÄ STTHealthChecker
    ‚îú‚îÄ‚îÄ TTSHealthChecker
    ‚îú‚îÄ‚îÄ LLMHealthChecker
    ‚îú‚îÄ‚îÄ ModulesHealthChecker
    ‚îî‚îÄ‚îÄ NetworkHealthChecker
```

#### 3.2 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è

```python
# utils/health_check.py
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
import asyncio

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"

@dataclass
class HealthCheckResult:
    component: str
    status: HealthStatus
    message: str
    timestamp: float
    details: Dict[str, any] = None
    
    def to_dict(self):
        return {
            "component": self.component,
            "status": self.status.value,
            "message": self.message,
            "timestamp": self.timestamp,
            "details": self.details or {}
        }

class STTHealthChecker:
    @staticmethod
    async def check(stt_engine, logger) -> HealthCheckResult:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ STT"""
        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Ç–µ—Å—Ç–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            result = await asyncio.wait_for(
                stt_engine.test_recognition("test"),
                timeout=3.0
            )
            
            if result:
                return HealthCheckResult(
                    component="stt",
                    status=HealthStatus.HEALTHY,
                    message="STT engine ready",
                    timestamp=time.time(),
                    details={"model": str(stt_engine.model_path)}
                )
            else:
                return HealthCheckResult(
                    component="stt",
                    status=HealthStatus.DEGRADED,
                    message="STT recognition returned empty",
                    timestamp=time.time()
                )
        except asyncio.TimeoutError:
            return HealthCheckResult(
                component="stt",
                status=HealthStatus.UNHEALTHY,
                message="STT timeout (>3s)",
                timestamp=time.time()
            )
        except Exception as e:
            logger.error(f"STT health check failed: {e}")
            return HealthCheckResult(
                component="stt",
                status=HealthStatus.UNHEALTHY,
                message=f"STT error: {str(e)[:100]}",
                timestamp=time.time()
            )

class TTSHealthChecker:
    @staticmethod
    async def check(tts_engine, logger) -> HealthCheckResult:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS"""
        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Å–∏–Ω—Ç–µ–∑ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            result = await asyncio.wait_for(
                tts_engine.speak("test"),
                timeout=3.0
            )
            
            if result:
                return HealthCheckResult(
                    component="tts",
                    status=HealthStatus.HEALTHY,
                    message="TTS engine ready",
                    timestamp=time.time(),
                    details={"engine": tts_engine.engine_name if hasattr(tts_engine, 'engine_name') else "unknown"}
                )
            else:
                return HealthCheckResult(
                    component="tts",
                    status=HealthStatus.DEGRADED,
                    message="TTS returned false",
                    timestamp=time.time()
                )
        except asyncio.TimeoutError:
            return HealthCheckResult(
                component="tts",
                status=HealthStatus.UNHEALTHY,
                message="TTS timeout (>3s)",
                timestamp=time.time()
            )
        except Exception as e:
            logger.error(f"TTS health check failed: {e}")
            return HealthCheckResult(
                component="tts",
                status=HealthStatus.UNHEALTHY,
                message=f"TTS error: {str(e)[:100]}",
                timestamp=time.time()
            )

class LLMHealthChecker:
    @staticmethod
    async def check(llm_client, logger) -> HealthCheckResult:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ LLM"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama
            result = await asyncio.wait_for(
                llm_client.check_ollama_health(),
                timeout=2.0
            )
            
            if result:
                return HealthCheckResult(
                    component="llm",
                    status=HealthStatus.HEALTHY,
                    message="LLM (Ollama) ready",
                    timestamp=time.time(),
                    details={"ollama_url": llm_client.ollama_url}
                )
            else:
                return HealthCheckResult(
                    component="llm",
                    status=HealthStatus.UNHEALTHY,
                    message="Ollama not responding",
                    timestamp=time.time()
                )
        except asyncio.TimeoutError:
            return HealthCheckResult(
                component="llm",
                status=HealthStatus.UNHEALTHY,
                message="Ollama timeout (>2s)",
                timestamp=time.time()
            )
        except Exception as e:
            logger.error(f"LLM health check failed: {e}")
            return HealthCheckResult(
                component="llm",
                status=HealthStatus.UNHEALTHY,
                message=f"LLM error: {str(e)[:100]}",
                timestamp=time.time()
            )

class HealthChecker:
    """–§–∞—Å–∞–¥ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, arvis_core, config, logger):
        self.arvis_core = arvis_core
        self.config = config
        self.logger = logger
        self.last_results: Dict[str, HealthCheckResult] = {}
        self._periodic_task = None
    
    async def check_all(self) -> List[HealthCheckResult]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
        tasks = []
        
        if self.arvis_core.stt_engine:
            tasks.append(STTHealthChecker.check(self.arvis_core.stt_engine, self.logger))
        
        if self.arvis_core.tts_engine:
            tasks.append(TTSHealthChecker.check(self.arvis_core.tts_engine, self.logger))
        
        if self.arvis_core.llm_client:
            tasks.append(LLMHealthChecker.check(self.arvis_core.llm_client, self.logger))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            if isinstance(result, HealthCheckResult):
                self.last_results[result.component] = result
        
        return [r for r in results if isinstance(r, HealthCheckResult)]
    
    async def check_component(self, component_name: str) -> HealthCheckResult:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç"""
        if component_name == "stt":
            return await STTHealthChecker.check(self.arvis_core.stt_engine, self.logger)
        elif component_name == "tts":
            return await TTSHealthChecker.check(self.arvis_core.tts_engine, self.logger)
        elif component_name == "llm":
            return await LLMHealthChecker.check(self.arvis_core.llm_client, self.logger)
        else:
            return HealthCheckResult(
                component=component_name,
                status=HealthStatus.UNKNOWN,
                message=f"Unknown component: {component_name}",
                timestamp=time.time()
            )
    
    def start_periodic_checks(self, interval_sec: int = 60):
        """–ù–∞—á–∞—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        from utils.async_manager import task_manager
        
        async def periodic_check():
            while True:
                try:
                    await asyncio.sleep(interval_sec)
                    results = await self.check_all()
                    
                    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –Ω–µ–∑–¥–æ—Ä–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                    unhealthy = [r for r in results if r.status == HealthStatus.UNHEALTHY]
                    if unhealthy:
                        self.logger.warning(f"Health check: {len(unhealthy)} unhealthy components")
                        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–∏–≥–Ω–∞–ª –≤ ArvisCore (–µ—Å–ª–∏ –µ—Å—Ç—å)
                        if hasattr(self.arvis_core, 'health_status_changed'):
                            self.arvis_core.health_status_changed.emit(results)
                
                except Exception as e:
                    self.logger.error(f"Periodic health check failed: {e}")
        
        self._periodic_task = task_manager.run_async("periodic_health_checks", periodic_check)
    
    def stop_periodic_checks(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        if self._periodic_task:
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å cancellation –≤ task_manager
            self._periodic_task = None
    
    def get_last_results(self) -> Dict[str, dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–æ–∫"""
        return {name: result.to_dict() for name, result in self.last_results.items()}
```

**[–ü–†–û–î–û–õ–ñ–ï–ù–ò–ï - –î–†–£–ì–ò–ï –§–ò–ß–ò]**

Due to token limit, –±—É–¥–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–∞–π–ª–µ. –°–æ–∑–¥–∞–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏:

---

## üîÑ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å

```
–§–ò–ß–ê 1: TTS Factory       (–î–µ–Ω—å 1-5)
    ‚Üì
–§–ò–ß–ê 2: LLM Streaming     (–î–µ–Ω—å 6-11, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å 4)
    ‚Üì
–§–ò–ß–ê 3: Health Checks     (–î–µ–Ω—å 12-15)
    ‚Üì (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 1-3)
–§–ò–ß–ê 5: Metrics Collector (–î–µ–Ω—å 16-19)
    ‚Üì
–§–ò–ß–ê 4: Split arvis_core  (–î–µ–Ω—å 10-16, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    ‚Üì
–§–ò–ß–ê 6: Unit Tests        (–î–µ–Ω—å 17-24, –ø–æ–∫—Ä—ã–≤–∞–µ—Ç 1-5)
    ‚Üì
–§–ò–ß–ê 7-9: PyQt6, Config, Notifications (–î–µ–Ω—å 25-30, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
```

## üß™ Testing Strategy

–î–ª—è –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏:
1. **Unit tests** (>80% coverage)
2. **Integration tests** (—Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏)
3. **Performance tests** (TTFT, throughput, latency)
4. **UI tests** (–¥–ª—è PyQt –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤)
5. **Regression tests** (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)

---

## üìä Post-Implementation Checklist

- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç (pytest —Å coverage)
- [ ] pre-commit —Ö—É–∫–∏ –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞
- [ ] CHANGELOG –æ–±–Ω–æ–≤–ª–µ–Ω
- [ ] Version bump (1.5.1 ‚Üí 1.6.0)
- [ ] Performance metrics –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —É–ª—É—á—à–µ–Ω–∏—è
- [ ] Code review –ø—Ä–æ–π–¥–µ–Ω
- [ ] Release notes –≥–æ—Ç–æ–≤—ã

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞**: 1.0 | **–û–±–Ω–æ–≤–ª–µ–Ω–æ**: 21 –æ–∫—Ç—è–±—Ä—è 2025
